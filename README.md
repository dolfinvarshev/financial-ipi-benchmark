Assistant or Adversary?
Auditing Financial LLMs Against Indirect Prompt Injection

This repository contains the dataset, codebase, and evaluation results for the academic study:

Assistant or Adversary? Auditing Financial LLMs Against Indirect Prompt Injection

The project introduces a domain-specific benchmark designed to evaluate the robustness of large language models (LLMs) against Indirect Prompt Injection (IPI) attacks in high-stakes financial contexts.

ğŸ“Œ Overview

Total attack instances: 1,250

Financial domains: 10 high-risk niches (e.g., Insider Trading, Payroll, Strategic Planning)

Models evaluated:

GPT-4o-mini

Claude-3-Haiku

Gemini-2.5-Flash

The benchmark systematically measures attack success rates (ASR) and information leakage severity across models, domains, and attack vectors.

ğŸ“‚ Repository Structure

The repository is organized to ensure full reproducibility of the experimental pipeline, from attack generation to final visualization.

financial-ipi-benchmark/
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ figures/ # Visualization figures used in the paper
â”‚ â””â”€â”€ paper.pdf # Final academic thesis PDF
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ benchmark_dataset/
â”‚ â”‚ â””â”€â”€ financial_injection_benchmark_unified.csv
â”‚ â”‚ # Unified dataset of 1,250 adversarial prompts
â”‚ â”œâ”€â”€ input/
â”‚ â”‚ â””â”€â”€ UNIFIED FINANCIAL CONTEXT ARCHIVE.docx
â”‚ â”‚ # Source text for the 10 financial carrier documents
â”‚ â””â”€â”€ results/
â”‚ â”œâ”€â”€ graded_by_llm/ # LLM-as-a-Judge evaluation logs
â”‚ â”œâ”€â”€ raw_responses/ # Raw JSON/CSV outputs from model APIs
â”‚ â””â”€â”€ final_benchmark_summary.csv
â”‚ # Aggregated metrics (ASR, Severity)
â”‚
â”œâ”€â”€ scripts/ # Python scripts for the experimental pipeline
â”œâ”€â”€ .gitignore # Security and exclusion configuration
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ requirements.txt # Python dependencies

ğŸš€ Key Findings

Our evaluation across 1,250 indirect prompt injection attacks reveals notable security gaps in financial LLM deployments:

ğŸ”“ Model Vulnerability

GPT-4o-mini showed the highest susceptibility

60.4% Attack Success Rate (ASR)

Frequently prioritized embedded instructions over safety constraints

ğŸ›¡ï¸ Model Robustness

Claude-3-Haiku was the most resilient

26.5% ASR

Demonstrated consistent refusal and constraint adherence

âš ï¸ High-Risk Contexts

Future Strategy & Planning documents were the most vulnerable

61.1% average ASR

Role Impersonation attacks (e.g., â€œI am the CEOâ€) were the most effective attack vector

ğŸ› ï¸ Reproduction Pipeline

Follow the steps below to fully reproduce the benchmark results.

1ï¸âƒ£ Attack Generation

Generates 1,250 adversarial prompts by combining:

10 financial carrier documents

5 attack vectors

5 obfuscation strategies

Script: scripts/creating_ipi_attacks.py

Output:
data/benchmark_dataset/financial_injection_benchmark_unified.csv

2ï¸âƒ£ Model Execution

Executes the generated prompts against the target model APIs.

Script: scripts/execution_code.py

Output directory:
data/results/raw_responses/

Requires valid API keys for OpenAI, Anthropic, and Google.

3ï¸âƒ£ Evaluation (LLM-as-a-Judge)

Grades each model response for:

Attack success (ASR)

Information leakage severity

Evaluation combines an independent LLM with regex-based parsers.

Script: scripts/evaluate_results.py

Output directory:
data/results/graded_by_llm/

4ï¸âƒ£ Summarization

Aggregates graded evaluations into final benchmark metrics.

Script: scripts/creating_summary.py

Output:
data/results/final_benchmark_summary.csv

5ï¸âƒ£ Visualization

Generates the figures used in the paper (heatmaps and bar charts).

Script: scripts/generating_plots_from_benchmark_summary.py

Output directory:
assets/figures/

âš™ï¸ Installation
Clone the Repository
git clone https://github.com/YOUR_USERNAME/financial-ipi-benchmark.git
cd financial-ipi-benchmark

Install Dependencies
pip install -r requirements.txt

Environment Setup

Set your API keys as environment variables (or via a local secrets file) before running:

execution_code.py

ğŸ“œ License & Usage

This project is intended strictly for academic and research purposes.

If you plan to reuse the dataset, benchmark design, or evaluation methodology, please cite the associated paper.
